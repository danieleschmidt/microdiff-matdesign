# Alerting rules and thresholds for MicroDiff-MatDesign
# This configuration defines comprehensive alerting for system health,
# performance issues, and business-critical failures

groups:
  
  # Critical System Alerts
  - name: critical_system_alerts
    interval: 30s
    rules:
      
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          team: platform
          category: availability
        annotations:
          summary: "Service {{ $labels.instance }} is down"
          description: |
            Service {{ $labels.instance }} has been down for more than 1 minute.
            This indicates a critical system failure requiring immediate attention.
          runbook_url: "https://docs.company.com/runbooks/service-down"
          dashboard_url: "https://grafana.company.com/d/service-overview"
          
      - alert: HighErrorRate
        expr: microdiff:error_rate_percent > 5
        for: 2m
        labels:
          severity: critical
          team: application
          category: errors
        annotations:
          summary: "High error rate detected: {{ $value }}%"
          description: |
            Error rate has exceeded 5% for more than 2 minutes.
            Current rate: {{ $value }}%
            This indicates serious application issues affecting users.
          runbook_url: "https://docs.company.com/runbooks/high-error-rate"
          
      - alert: DatabaseConnectionFailure
        expr: postgres_up == 0
        for: 30s
        labels:
          severity: critical
          team: database
          category: connectivity
        annotations:
          summary: "Database connection failure"
          description: |
            Cannot connect to PostgreSQL database.
            This will cause complete service failure.
          runbook_url: "https://docs.company.com/runbooks/database-down"
          
      - alert: OutOfMemory
        expr: microdiff:memory_usage_percent > 95
        for: 1m
        labels:
          severity: critical
          team: platform
          category: resources
        annotations:
          summary: "System running out of memory: {{ $value }}%"
          description: |
            Memory usage has exceeded 95% for more than 1 minute.
            System may become unresponsive or crash.
            Current usage: {{ $value }}%
          runbook_url: "https://docs.company.com/runbooks/out-of-memory"
          
      - alert: DiskSpaceCritical
        expr: microdiff:disk_usage_percent > 95
        for: 1m
        labels:
          severity: critical
          team: platform
          category: storage
        annotations:
          summary: "Critical disk space: {{ $value }}% used"
          description: |
            Disk space usage has exceeded 95%.
            System may fail to write logs or temporary files.
            Immediate cleanup required.
          runbook_url: "https://docs.company.com/runbooks/disk-space-critical"

  # Performance Alerts
  - name: performance_alerts
    interval: 60s
    rules:
      
      - alert: HighResponseTime
        expr: microdiff:response_time_95th_percentile > 2
        for: 5m
        labels:
          severity: warning
          team: application
          category: performance
        annotations:
          summary: "High response time: {{ $value }}s (95th percentile)"
          description: |
            95th percentile response time has exceeded 2 seconds for 5 minutes.
            This indicates performance degradation affecting user experience.
          runbook_url: "https://docs.company.com/runbooks/high-response-time"
          
      - alert: SlowModelInference
        expr: histogram_quantile(0.95, rate(microdiff_model_inference_duration_seconds_bucket[5m])) > 10
        for: 3m
        labels:
          severity: warning
          team: ml
          category: performance
        annotations:
          summary: "Slow model inference: {{ $value }}s (95th percentile)"
          description: |
            Model inference time has exceeded 10 seconds for 3 minutes.
            This may indicate GPU resource constraints or model loading issues.
          runbook_url: "https://docs.company.com/runbooks/slow-inference"
          
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          team: platform
          category: resources
        annotations:
          summary: "High CPU usage: {{ $value }}%"
          description: |
            CPU usage has exceeded 80% for 5 minutes.
            This may impact application performance.
          runbook_url: "https://docs.company.com/runbooks/high-cpu"
          
      - alert: HighGPUUtilization
        expr: microdiff_model_gpu_utilization_percent > 95
        for: 3m
        labels:
          severity: warning
          team: ml
          category: resources
        annotations:
          summary: "High GPU utilization: {{ $value }}%"
          description: |
            GPU utilization has exceeded 95% for 3 minutes.
            This may cause inference delays or failures.
          runbook_url: "https://docs.company.com/runbooks/high-gpu-usage"

  # Application Health Alerts
  - name: application_health_alerts
    interval: 60s
    rules:
      
      - alert: ModelLoadingFailure
        expr: increase(microdiff_model_errors_total[5m]) > 5
        for: 1m
        labels:
          severity: warning
          team: ml
          category: models
        annotations:
          summary: "Model loading failures detected"
          description: |
            More than 5 model loading failures in the last 5 minutes.
            This indicates issues with model initialization or resource constraints.
          runbook_url: "https://docs.company.com/runbooks/model-loading-failure"
          
      - alert: ImageProcessingErrors
        expr: rate(microdiff_image_processing_errors_total[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
          team: application
          category: processing
        annotations:
          summary: "High image processing error rate"
          description: |
            Image processing error rate has exceeded 0.1 errors/second for 2 minutes.
            This may indicate issues with input data or processing pipeline.
          runbook_url: "https://docs.company.com/runbooks/image-processing-errors"
          
      - alert: QueueBacklog
        expr: microdiff_queue_size > 100
        for: 5m
        labels:
          severity: warning
          team: application
          category: throughput
        annotations:
          summary: "Processing queue backlog: {{ $value }} items"
          description: |
            Processing queue has more than 100 items for 5 minutes.
            This indicates throughput issues or resource constraints.
          runbook_url: "https://docs.company.com/runbooks/queue-backlog"
          
      - alert: LowCacheHitRate
        expr: microdiff_cache_hit_rate_percent < 80
        for: 10m
        labels:
          severity: info
          team: application
          category: optimization
        annotations:
          summary: "Low cache hit rate: {{ $value }}%"
          description: |
            Cache hit rate has fallen below 80% for 10 minutes.
            This may indicate cache invalidation issues or insufficient cache size.
          runbook_url: "https://docs.company.com/runbooks/low-cache-hit-rate"

  # Security Alerts
  - name: security_alerts
    interval: 30s
    rules:
      
      - alert: UnauthorizedAccess
        expr: increase(microdiff_requests_total{status_code=~"401|403"}[5m]) > 10
        for: 1m
        labels:
          severity: warning
          team: security
          category: access
        annotations:
          summary: "Multiple unauthorized access attempts"
          description: |
            More than 10 unauthorized access attempts in the last 5 minutes.
            This may indicate a security attack or misconfigured clients.
          runbook_url: "https://docs.company.com/runbooks/unauthorized-access"
          
      - alert: SuspiciousActivity
        expr: increase(microdiff_requests_total{endpoint=~"/admin.*"}[1m]) > 5
        for: 30s
        labels:
          severity: critical
          team: security
          category: access
        annotations:
          summary: "Suspicious admin endpoint access"
          description: |
            More than 5 admin endpoint accesses in 1 minute.
            This requires immediate investigation.
          runbook_url: "https://docs.company.com/runbooks/suspicious-activity"

  # Business Logic Alerts
  - name: business_alerts
    interval: 300s  # 5 minutes
    rules:
      
      - alert: LowSuccessRate
        expr: |
          (
            rate(microdiff_designs_generated_total{success="true"}[15m]) /
            rate(microdiff_designs_generated_total[15m])
          ) * 100 < 90
        for: 10m
        labels:
          severity: warning
          team: application
          category: business
        annotations:
          summary: "Low design generation success rate: {{ $value }}%"
          description: |
            Design generation success rate has fallen below 90% for 10 minutes.
            This indicates issues with the core business functionality.
          runbook_url: "https://docs.company.com/runbooks/low-success-rate"
          
      - alert: UnusualTrafficPattern
        expr: |
          abs(
            rate(microdiff_requests_total[5m]) -
            rate(microdiff_requests_total[5m] offset 1w)
          ) / rate(microdiff_requests_total[5m] offset 1w) > 0.5
        for: 15m
        labels:
          severity: info
          team: application
          category: traffic
        annotations:
          summary: "Unusual traffic pattern detected"
          description: |
            Current traffic differs by more than 50% from same time last week.
            This may indicate viral content, attacks, or system issues.
          runbook_url: "https://docs.company.com/runbooks/unusual-traffic"

# Notification routing configuration
route:
  group_by: ['alertname', 'team']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  receiver: 'default'
  
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      repeat_interval: 1h
      
    - match:
        team: security
      receiver: 'security-team'
      group_wait: 15s
      repeat_interval: 2h
      
    - match:
        team: ml
      receiver: 'ml-team'
      group_wait: 30s
      repeat_interval: 4h
      
    - match:
        category: business
      receiver: 'business-team'
      group_wait: 60s
      repeat_interval: 24h

# Alert receivers and notification channels
receivers:
  
  - name: 'default'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts'
        title: 'MicroDiff-MatDesign Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Severity:* {{ .Labels.severity }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        
  - name: 'critical-alerts'
    pagerduty_configs:
      - routing_key: '${PAGERDUTY_ROUTING_KEY}'
        description: 'Critical alert from MicroDiff-MatDesign'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL_CRITICAL}'
        channel: '#critical-alerts'
        title: '🚨 CRITICAL ALERT 🚨'
        text: |
          {{ range .Alerts }}
          *CRITICAL:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Runbook:* {{ .Annotations.runbook_url }}
          *Dashboard:* {{ .Annotations.dashboard_url }}
          {{ end }}
        
  - name: 'security-team'
    email_configs:
      - to: 'security@company.com'
        subject: 'Security Alert: MicroDiff-MatDesign'
        body: |
          Security alert from MicroDiff-MatDesign:
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Severity: {{ .Labels.severity }}
          Description: {{ .Annotations.description }}
          Runbook: {{ .Annotations.runbook_url }}
          {{ end }}
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_SECURITY}'
        channel: '#security-alerts'
        
  - name: 'ml-team'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_ML}'
        channel: '#ml-alerts'
        title: 'ML System Alert'
        
  - name: 'business-team'
    email_configs:
      - to: 'business@company.com'
        subject: 'Business Metric Alert: MicroDiff-MatDesign'

# Alert inhibition rules (prevent alert spam)
inhibit_rules:
  
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
    
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '.*'
    equal: ['instance']

# Global alert configuration
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@company.com'
  slack_api_url: '${SLACK_WEBHOOK_URL}'
  
# Alert template customization
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Testing and validation
test_alerts:
  
  # Test critical alert
  - name: test_critical_alert
    command: |
      curl -X POST http://localhost:9093/api/v1/alerts \
      -H "Content-Type: application/json" \
      -d '[{
        "labels": {
          "alertname": "TestCriticalAlert",
          "severity": "critical",
          "instance": "test"
        },
        "annotations": {
          "summary": "Test critical alert",
          "description": "This is a test critical alert"
        }
      }]'
      
  # Test performance alert
  - name: test_performance_alert
    command: |
      curl -X POST http://localhost:9093/api/v1/alerts \
      -H "Content-Type: application/json" \
      -d '[{
        "labels": {
          "alertname": "TestPerformanceAlert",
          "severity": "warning",
          "team": "application"
        },
        "annotations": {
          "summary": "Test performance alert",
          "description": "This is a test performance alert"
        }
      }]'